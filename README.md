# Insurance Premium Prediction

## Project Overview

This project predicts insurance premium amounts using advanced machine learning techniques. The workflow includes extensive feature engineering, data preprocessing, model training with LightGBM, cross-validation, and ensemble predictions. The project also provides feature importance analysis and outputs predictions in a CSV file.

---

## Directory Structure

```
.
├── data/
│   ├── train.csv
│   ├── test.csv
│   └── sample_submission.csv
├── insurance_premium_prediction.py
├── predictions.csv
├── feature_importance.png
├── requirements.txt
```

- **data/**: Contains the training, test, and sample submission datasets.
- **insurance_premium_prediction.py**: Main script for data processing, feature engineering, model training, and prediction.
- **predictions.csv**: Output file with predicted insurance premiums.
- **feature_importance.png**: Visualization of feature importances (generated by the script).
- **requirements.txt**: List of required Python packages.

---

## Data Description

- **train.csv**: Training data with features and target variable (`Premium Amount`).
- **test.csv**: Test data for which predictions are to be made.
- **sample_submission.csv**: Example format for the submission file.

Key features include:
- Demographics (Age, Number of Dependents)
- Financial (Annual Income, Credit Score)
- Health (Health Score)
- Policy details (Policy Start Date, Insurance Duration, Previous Claims, Vehicle Age)

---

## Main Features & Workflow

1. **Data Loading & Exploration**
   - Loads training and test datasets.
   - Displays sample data and checks for missing values.

2. **Feature Engineering**
   - Date features: Extracts year, month, day, weekday, quarter, etc. from policy start date.
   - Numerical transformations: Log, square, cube, and binning for age, income, health, credit, duration, claims, vehicle age, and dependents.
   - Interaction features: Combinations and ratios of key features.

3. **Preprocessing**
   - Handles missing values (median for numerics, mode for categoricals).
   - Power transformation (Yeo-Johnson) for normalization.
   - One-hot encoding for categorical variables.
   - Ensures train and test sets have matching columns.

4. **Model Training**
   - Uses LightGBM with cross-validation (KFold).
   - Trains multiple models and averages their predictions.
   - Evaluates using RMSLE (Root Mean Squared Logarithmic Error).

5. **Prediction & Output**
   - Makes predictions on the test set.
   - Averages predictions from ensemble and final model.
   - Outputs results to `predictions.csv`.

6. **Feature Importance**
   - Calculates and displays the most important features.
   - Saves a feature importance plot (`feature_importance.png`).

---

## Requirements

- Python 3.7+
- pandas >= 1.3.0
- numpy >= 1.20.0
- scikit-learn >= 0.24.0
- matplotlib >= 3.4.0
- seaborn >= 0.11.0
- lightgbm

Install dependencies with:
```bash
pip install -r requirements.txt
```

---

## Usage

1. **Prepare Data**
   - Place `train.csv` and `test.csv` in the `data/` directory.

2. **Run the Script**
   ```bash
   python insurance_premium_prediction.py
   ```

3. **Output**
   - Predictions will be saved to `predictions.csv`.
   - Feature importance plot will be saved as `feature_importance.png`.

---

## Results

- The script prints cross-validation RMSLE scores and the top 10 most important features.
- The output file `predictions.csv` contains two columns: `id` and `premium`.

---

## Notes

- The script uses log transformation on the target variable for better model performance.
- Extensive feature engineering is performed for improved accuracy.
- The project is designed for reproducibility and can be extended with additional models or features. 